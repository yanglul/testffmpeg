use crossbeam_channel::{Receiver, Sender, bounded, select, tick};
use ffmpeg_next::codec::Context as CodecContext;
use ffmpeg_next::format::Pixel;
use ffmpeg_next::format::{Context, input};
use ffmpeg_next::frame::Video;
use ffmpeg_next::software::scaling::Context as scaling_context;
use sdl2::pixels::Color;
use sdl2::video::Window;
use std::time::{Duration, Instant};
use std::{
    fmt::Debug,
    sync::{Arc, Mutex},
};
mod audio;
mod video;
fn main() {
    let file = &std::env::args().nth(1).expect("Cannot open file.");
    // let _ = audio::play_mp4(file);
    ffmpeg_next::init().unwrap();
    // 打开输入文件
    let mut ictx = input(&file).unwrap();
    // 查找视频流
    let video_stream = ictx
        .streams()
        .best(ffmpeg_next::media::Type::Video)
        .ok_or(anyhow::anyhow!("No video stream found"))
        .unwrap();

    let audio_stream = ictx
        .streams()
        .best(ffmpeg_next::media::Type::Audio)
        .ok_or(anyhow::anyhow!("No video stream found"))
        .unwrap();

    let audio_stream_index = audio_stream.index();
    let video_stream_index = video_stream.index();
    let duration = ictx.duration(); //总时长
    println!("duration {}", duration);
    let context = CodecContext::from_parameters(video_stream.parameters()).unwrap();
    let time_base = video_stream.time_base();
//     let frame_rate = video_stream.avg_frame_rate();
//     println!(
//         "frame_rate cac duration {}",
//         frame_rate.denominator() * 1000 / frame_rate.numerator()
//     );

    let total_frams = video_stream.frames();
    println!("total_frams {}", duration / total_frams);

    // let start = Instant::now();
    // // 结束计时并计算耗时
    // let duration = start.elapsed();
    let fduration = duration / total_frams;
    // Open the file
    //     let mut viter = video::Videor::new(
    //         context,
    //         total_frams as usize,
    //         video_stream_index,
    //         fduration as u64,
    //     )
    //     .unwrap();
    let mut i_iter = ictx.packets();

    // 初始化 SDL2
    let sdl_context = sdl2::init().unwrap();
    let video_subsystem = sdl_context.video().unwrap();
    // 获取解码器上下文

    let mut decoder_context = context.decoder().video().unwrap();

    let width = decoder_context.width();
    let height = decoder_context.height();
    // 创建 SDL2 窗口和画布
    let window = video_subsystem
        .window("FFmpeg + SDL2 Video Player", width, height)
        .position_centered()
        .build()
        .unwrap();
    let mut canvas = window.into_canvas().build().unwrap();
    canvas.set_draw_color(Color::BLACK);
    canvas.clear();
    canvas.present();

    // 初始化缩放上下文
    let  mut scaling_context = ffmpeg_next::software::scaling::Context::get(
        decoder_context.format(),
        width,
        height,
        Pixel::RGB24,
        width,
        height,
        ffmpeg_next::software::scaling::Flags::BILINEAR,
    )
    .unwrap();
    let mut frame_buffer = Vec::new();
    let mut current_frame_index = 0;
    loop {
        let (stream, mut packet) = i_iter.next().expect("遍历文件失败");
        let ist_index = stream.index();
        if packet.stream() == video_stream_index {
            // 发送包到解码器
            decoder_context.send_packet(&packet).unwrap();

            // 接收解码后的帧
            let mut decoded_frame = Video::empty();
            if decoder_context.receive_frame(&mut decoded_frame).is_ok() {
                // 缩放帧到RGB格式
                let mut rgb_frame = Video::empty();
                scaling_context.run(&decoded_frame, &mut rgb_frame).unwrap();

                // 保存帧数据到缓冲区
                frame_buffer.push(rgb_frame);
               {
                    if current_frame_index>= frame_buffer.len(){
                        std::thread::sleep(Duration::from_nanos(fduration as u64));
                        continue;
                    }
                    let rgb_frame = frame_buffer.get(current_frame_index).unwrap();
                    canvas.clear();
                    let texture_creator = canvas.texture_creator();
                    let mut texture = texture_creator.create_texture_target(
                        sdl2::pixels::PixelFormatEnum::RGB24,
                        rgb_frame.width() as u32,
                        rgb_frame.height() as u32,
                    ).unwrap();
                    texture.update(None, &rgb_frame.data(ist_index), rgb_frame.stride(ist_index) as usize).unwrap();
                    canvas.copy(&texture, None, None).unwrap();
                    canvas.present();
                    current_frame_index +=1;
                    std::thread::sleep(Duration::from_nanos(duration as u64));
               }
                 
            }
        } 
    }
}

struct VideoPlayer {
    current_frame: Video,
    is_playing: bool,
    last_update: Instant,
}

pub enum Vstate {
    Playing,
    Pause,
    Stop,
}
